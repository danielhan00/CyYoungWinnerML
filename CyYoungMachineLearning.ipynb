{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLHP30b-DaBB"
      },
      "source": [
        "<center> <h2> DS 3000 - Fall 2021</h2> </center>\n",
        "<center> <h3> DS Report </h3> </center>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTVfM3pUDaBD"
      },
      "source": [
        "<center> <h3>Can We Predict the Winner of the Cy Young Award?</h3> </center>\n",
        "<center><h4>Daniel Han, Karenna Ng, Hannah Szeto</h4></center>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlYJPxOSDaBE"
      },
      "source": [
        "<hr style=\"height:2px; border:none; color:black; background-color:black;\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXVKjFtrDaBE"
      },
      "source": [
        "#### Executive Summary:\n",
        "\n",
        "&emsp;&emsp;Every season, the Cy Young Award is awarded to the two best pitchers in Major League Baseball. With baseball having perhaps the most commprehensive database in all of professional sports, analyzing that data should tell us who deserves to win the Cy Young based on statistics. So, in this project, we decided to compile pitching data from 2016-2019 to train a machine learning model to predict who actually deserves to win the Cy Young Award based on how previous years' winners won.\n",
        "\n",
        "&emsp;&emsp;After cleaning and merging data from baseball-reference.com, it was time to train our model. Our imperfect and imbalanced dataset led us to choose cross validation and resampling to train our model. However, after our best efforts to fit our data properly and tune for hyperparameters, the problems with our dataset proved to be too much of an obstacle for the machine learning algorithms. Ultimately, we were unable to make a confident prediction for this year's Cy Young Award winners, but an even further exploration of our work could possibly yield more pertinent results.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtWDDqxxDaBF"
      },
      "source": [
        "<hr style=\"height:2px; border:none; color:black; background-color:black;\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tir_FFgwDaBF"
      },
      "source": [
        "## Outline\n",
        "1. <a href='#1'>INTRODUCTION</a>\n",
        "2. <a href='#2'>METHOD</a>\n",
        "3. <a href='#3'>RESULTS</a>\n",
        "4. <a href='#4'>DISCUSSION</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwPZPA7bDaBG"
      },
      "source": [
        "<a id=\"1\"></a>\n",
        "<hr style=\"height:2px; border:none; color:black; background-color:black;\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_feD9-J0DaBG"
      },
      "source": [
        "## 1. INTRODUCTION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vq9aoybxDaBH"
      },
      "source": [
        "&emsp;&emsp;Using advanced statistics and data made available by Major League Baseball, we would like\n",
        "to predict this year’s (2021) Cy Young winners. The problem is that baseball statistics are detailed\n",
        "and granular, yet there is so much variance on opinions and awards given. In other words, shouldn’t the vast statistical data and insights available from that data provide objective data on who the best pitchers in Major League Baseball are? Through an exploration of data from the last five years of baseball, a clear picture of who deserves the 2021 Cy Young Awards should emerge. \n",
        "\n",
        "\n",
        "<h4>Problem Statement</h4>\n",
        "\n",
        "&emsp;&emsp;Every year in Major League Baseball, the best pitcher from each conference, American and National League, is presented with the Cy Young Award. The criteria for this award is subjective; the Baseball Writers Association of America votes on the best pitchers in each league to give the award to. However, not every year do the best pitchers in baseball actually win the Cy Young Award. So, there must be a way to predict and choose the best pitchers in baseball according to the criteria used in previous years. \n",
        "\n",
        "&emsp;&emsp;This project attempts to bridge the gap between statistics and who deserves to win the Cy Young Award in 2021, based on previous years' results and data. Thus, an accurate prediction should be able to be made concerning this year's award!\n",
        "\n",
        "\n",
        "\n",
        "&emsp;&emsp;We would like to explore what data truly indicates great performance for a pitcher in Major League Baseball. This means exploring different types of data for pitchers including ERA, WHIP, Wins and Losses, etc. Doing so should increase our understanding of the game of baseball as well as make informed opinions and decisions regarding the sport!\n",
        "\n",
        "&emsp;&emsp;The Cy Young Award is an award given out every year that crowns the best pitchers in Major League Baseball. This award comes with fame, huge contracts, and of course, the honor of being named one of the best pitchers in baseball. So, this award should be given fairly based on available statistics, since so much is at stake. The problem, although not a problem that might affect society in some deep manner, still can be solved through an analysis and machine learning driven solution to properly award the Cy Young award to the right pitchers.\n",
        "\n",
        "&emsp;&emsp;Insights from this project could be useful for a variety of applications. First, simply predicting who the rightful winner of the Cy Young Award is a fun thing to do! MLB and the voters for the Cy Young Award could also use insights gained from this project to vote or change the decision process for the Award itself. Finally, sports bettors could use the insights gained from this project to make more edcuated decisions when placing bets! \n",
        "\n",
        "&emsp;&emsp;One such dive into the Cy Young award winner is a look into the 2018 Cy Young race. Using the xgboost algorithm, which is a popular machine learning algorithm, Robert Pollack, a sports data scientist, cleaned and analyzed data over the course of 17 seasons to attempt to make a prediction of the 2018 Cy Young Winner. Pollack's model identified 21 of 22 winners and 661 of 662 non-winners. So, the precision, recall, and F1 scores were all 0.95 out of 1.00. Notably, though, his model did not predict the 2018 winner itself correctly. Max Scherzer was projected to win according to Pollack's model, but Jacob DeGrom won by an overwhelming 29/30 first place votes in reality! So was not only his xgboost algortihm wrong for the 2018 prediction, it was extremely wrong! \n",
        "\n",
        "Pollack, R. (2018, November 14). Predicting the 2018 Cy Young Race with Machine Learning. Retrieved from https://tht.fangraphs.com/cy-young-award-2018-blake-snell-jacob-degrom-max-scherzer/ \n",
        "\n",
        "<h4>Questions</h4>\n",
        "  \n",
        "&emsp;&emsp;While considering the process and purpose behind this project, some significant questions came up. Who are the best pitchers in baseball? What features are most significant when evaluating pitchers? Which machine learning techniques are most accurate? Precise? LinearSVC? KNN Classification? GridSearchCV? Decision Tree? Is this a classification problem?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewaPL_XZDaBI"
      },
      "source": [
        "<a id=\"2\"></a>\n",
        "<hr style=\"height:2px; border:none; color:black; background-color:black;\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kToYBDz5DaBI"
      },
      "source": [
        "## 2. METHOD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQmBr-yzDaBI"
      },
      "source": [
        "### 2.1. Data Acquisition\n",
        " \n",
        "&emsp;&emsp; Our data was compiled from https://www.baseball-reference.com/, a comprehsive database for Professional American baseball. This site is the main source of statistics for historical and current baseball data. For the purpose of this project, we needed siginficant amounts of data, so we chose to extract standard and starting pitching data for the years 2016-2021 (excluding 2020 due to the COVID-19 shortened season). We also compiled the winner data from baseball-reference.com for the Cy Young Award for the years 2016-2021. \n",
        "\n",
        "&emsp;&emsp; Once the data was collected, it was time to clean and join the data to prepare it for learning and training. The first thing to do was to join the standard and starting pitching data per year. Standard pitching presents every pitcher's pitching statistics, such as ERA (earned run average), WHIP (walks/htis per innings pitched), as well as Wins and Losses. Starting pitching data presents only starting pitcher data as well as more detailed statistics such as Quality wins and adjusted wins. Once joining standard and starting pitching data, it was time to remove unnecessary features. This was done in conjunction with the research we had done to determine which features were important. Finally, adding the Cy Young winner data to that joined dataframe was done as the last step in preparing our data for learning. \n",
        "\n",
        "&emsp;&emsp; So, after cleaning and joining data from different sources on https://www.baseball-reference.com/, we were left with one merged_df with many features and variables. This merged dataframe lists every pitcher from the years 2016-2019, their relevant statistics, and whether or not they won the Cy Young Award in that year. There are 46 columns of statisitcal data per pitcher, and 156 pitchers worth of data. More detail about cleaning and the merged_df is described in our Results section.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# import datasets\n",
        "# repo: https://github.com/danielhan60903/DS3000FP \n",
        "  \n",
        "url2016 = 'https://raw.githubusercontent.com/danielhan60903/DS3000FP/main/2016_starting_pitchers.csv'\n",
        "df2016 = pd.read_csv(url2016)\n",
        "\n",
        "url2017 = 'https://raw.githubusercontent.com/danielhan60903/DS3000FP/main/2017_starting_pitchers.csv'\n",
        "df2017 = pd.read_csv(url2017)\n",
        "\n",
        "url2018 = 'https://raw.githubusercontent.com/danielhan60903/DS3000FP/main/2018_starting_pitchers.csv'\n",
        "df2018 = pd.read_csv(url2018)\n",
        "\n",
        "url2019 = 'https://raw.githubusercontent.com/danielhan60903/DS3000FP/main/2019_starting_pitchers.csv'\n",
        "df2019 = pd.read_csv(url2019)\n",
        "\n",
        "url2021 = 'https://raw.githubusercontent.com/danielhan60903/DS3000FP/main/2021_starting_pitchers.csv'\n",
        "df2021 = pd.read_csv(url2021)\n",
        "\n",
        "stdURL2016 = 'https://raw.githubusercontent.com/danielhan60903/DS3000FP/main/std2016.csv'\n",
        "std2016 = pd.read_csv(stdURL2016)\n",
        "\n",
        "stdURL2017 = 'https://raw.githubusercontent.com/danielhan60903/DS3000FP/main/std2017.csv'\n",
        "std2017 = pd.read_csv(stdURL2017)\n",
        "\n",
        "stdURL2018 = 'https://raw.githubusercontent.com/danielhan60903/DS3000FP/main/std2018.csv'\n",
        "std2018 = pd.read_csv(stdURL2018)\n",
        "\n",
        "stdURL2019 = 'https://raw.githubusercontent.com/danielhan60903/DS3000FP/main/std2019.csv'\n",
        "std2019 = pd.read_csv(stdURL2019)\n",
        "\n",
        "stdURL2021 = 'https://raw.githubusercontent.com/danielhan60903/DS3000FP/main/std2021.csv'\n",
        "std2021 = pd.read_csv(stdURL2021)\n",
        "\n",
        "urlWinner = 'https://raw.githubusercontent.com/danielhan60903/DS3000FP/main/cy_young_award_winners.csv'\n",
        "dfWinner = pd.read_csv(urlWinner, header=1, index_col=0)"
      ],
      "metadata": {
        "id": "sPLhrwIbJfVs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyDItinyDaBJ"
      },
      "source": [
        "### 2.2. Data Analysis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "&emsp;&emsp;We are going to predict whether a player is a Cy Young winner from various baseball stats including wins, losses, earned run average, saves, hits, runs, earned runs, home runs, strikeouts, hit-by-pitch, balk, wild pitch, batters faced, adjusted earned run average, fielding independent pitching, walks and hits per innings pitched, hits per nine innings, and home runs per nine innings. These are important predictors because they demonstrate how good of a pitcher/player someone is, which indicates the likelihood of them winning the Cy Young prize.\n",
        "\n",
        "&emsp;&emsp;This is a supervised ML problem because we are feeding labelled data to the algorithm to train it, as opposed to unsupervised learning, where you feed unlabelled data to the algorithm and allow it to find patterns/classes on its own. Additionally, we are tackling a classification problem, because we’re classifying players as either a Cy Young winner or not a Cy Young winner. In regression, the algorithm predicts a continuous value, as opposed to our case, where we are sorting the data into two discrete class labels.\n",
        "\n",
        "&emsp;&emsp;We are planning on trying Support Vector Machine (SVM), Decision Tree classifier, k-Nearest Neighbors (kNN), and Logistic Regression, since these algorithms all can be applied to a classification problem. An SVM algorithm finds a distinct line between data points, which works for our data since we are dividing our data into two classes. A decision tree classifier uses a series of if/else statements to split up the data into various classes, which could be useful to determine which features designate a data point as one class or the other. kNN finds the data points most similar to a data point and assigns it a class based on the classification of its nearest neighbors. This could be useful to see how dissimilar the two classes are, but it might be difficult to use as the final algorithm since there are so few “winners” that it might be difficult for the algorithm to successfully classify a player as a winner."
      ],
      "metadata": {
        "id": "fcX6eH2uFVTf"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLBahyc3DaBJ"
      },
      "source": [
        "<a id=\"3\"></a>\n",
        "<hr style=\"height:2px; border:none; color:black; background-color:black;\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zq5FTw0qDaBJ"
      },
      "source": [
        "## 3. RESULTS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoCgURUCDaBJ"
      },
      "source": [
        "### 3.1. Data Wrangling\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### _Reformatting Names and Dropping Duplicates_\n",
        "We noticed that it was very difficult to query the dataframes because there were hidden characters ('\\xa0') and asterisks (*) at the ends of some names. We cleaned up these strings to make searching and merging easier.\n",
        "The dataset also has some multiple entries per year for a single player if they were traded in the middle of the season. We removed all duplicate players, as we decided that being traded would remove a player from Cy Young award eligibility for our algorithm."
      ],
      "metadata": {
        "id": "3o70P1cWJKG0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# formats the given string, used for Name column\n",
        "def format_name(name):\n",
        "    name = name.replace('*', '')\n",
        "    name = name.replace('\\xa0', ' ')\n",
        "    return name"
      ],
      "metadata": {
        "id": "DL4Zty0wJJgk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "format_name('Andrew\\xa0Albers*')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "FTJNlpL4JUvH",
        "outputId": "1730c416-4a11-486d-9d57-32cc32e45067"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Andrew Albers'"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# apply formatting (names, dropping duplicates) inplace to both dfs for each year\n",
        "def format_df_names(df):\n",
        "    df[\"Name\"] = df[\"Name\"].map(format_name)\n",
        "    df.drop_duplicates(subset = 'Name', keep = False, inplace = True)\n",
        "    return df"
      ],
      "metadata": {
        "id": "uwvxJqAmJX3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2016.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "oAhG3h-bJar4",
        "outputId": "0167a8a4-c4d5-47c7-affe-29373718c5e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Rk</th>\n",
              "      <th>Name</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tm</th>\n",
              "      <th>IP</th>\n",
              "      <th>G</th>\n",
              "      <th>GS</th>\n",
              "      <th>Wgs</th>\n",
              "      <th>Lgs</th>\n",
              "      <th>ND</th>\n",
              "      <th>Wchp</th>\n",
              "      <th>Ltuf</th>\n",
              "      <th>Wtm</th>\n",
              "      <th>Ltm</th>\n",
              "      <th>tmW-L%</th>\n",
              "      <th>Wlst</th>\n",
              "      <th>Lsv</th>\n",
              "      <th>CG</th>\n",
              "      <th>SHO</th>\n",
              "      <th>QS</th>\n",
              "      <th>QS%</th>\n",
              "      <th>GmScA</th>\n",
              "      <th>Best</th>\n",
              "      <th>Wrst</th>\n",
              "      <th>BQR</th>\n",
              "      <th>BQS</th>\n",
              "      <th>sDR</th>\n",
              "      <th>lDR</th>\n",
              "      <th>RS/GS</th>\n",
              "      <th>RS/IP</th>\n",
              "      <th>IP/GS</th>\n",
              "      <th>Pit/GS</th>\n",
              "      <th>&lt;80</th>\n",
              "      <th>80-99</th>\n",
              "      <th>100-119</th>\n",
              "      <th>≥120</th>\n",
              "      <th>Max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Tim Adleman</td>\n",
              "      <td>28</td>\n",
              "      <td>CIN</td>\n",
              "      <td>69.2</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>6.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.462</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>38%</td>\n",
              "      <td>51.4</td>\n",
              "      <td>65</td>\n",
              "      <td>40</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>4.8</td>\n",
              "      <td>5.2</td>\n",
              "      <td>5.4</td>\n",
              "      <td>85</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Andrew Albers*</td>\n",
              "      <td>30</td>\n",
              "      <td>MIN</td>\n",
              "      <td>17.0</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0%</td>\n",
              "      <td>34.0</td>\n",
              "      <td>41</td>\n",
              "      <td>27</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6.4</td>\n",
              "      <td>14.1</td>\n",
              "      <td>3.3</td>\n",
              "      <td>73</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Matt Albers</td>\n",
              "      <td>33</td>\n",
              "      <td>CHW</td>\n",
              "      <td>51.1</td>\n",
              "      <td>58</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0%</td>\n",
              "      <td>53.0</td>\n",
              "      <td>53</td>\n",
              "      <td>53</td>\n",
              "      <td>24</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>25</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Raul Alcantara</td>\n",
              "      <td>23</td>\n",
              "      <td>OAK</td>\n",
              "      <td>22.1</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.200</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0%</td>\n",
              "      <td>40.2</td>\n",
              "      <td>54</td>\n",
              "      <td>22</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>4.2</td>\n",
              "      <td>4.3</td>\n",
              "      <td>4.5</td>\n",
              "      <td>76</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Brett Anderson*</td>\n",
              "      <td>28</td>\n",
              "      <td>LAD</td>\n",
              "      <td>11.1</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.333</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0%</td>\n",
              "      <td>26.0</td>\n",
              "      <td>40</td>\n",
              "      <td>16</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3.8</td>\n",
              "      <td>0.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>53</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>72</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Rk             Name  Age   Tm    IP  ...  <80  80-99  100-119  ≥120  Max\n",
              "0   1      Tim Adleman   28  CIN  69.2  ...    4      8        1     0  101\n",
              "1   2   Andrew Albers*   30  MIN  17.0  ...    1      1        0     0   88\n",
              "2   3      Matt Albers   33  CHW  51.1  ...    1      0        0     0   25\n",
              "3   4   Raul Alcantara   23  OAK  22.1  ...    3      1        1     0  104\n",
              "4   5  Brett Anderson*   28  LAD  11.1  ...    3      0        0     0   72\n",
              "\n",
              "[5 rows x 37 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "format_df_names(df2016).head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "id": "jF8SyRX8Jja7",
        "outputId": "5c72fb2b-77a5-4559-f1ed-2ef0009882f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Rk</th>\n",
              "      <th>Name</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tm</th>\n",
              "      <th>IP</th>\n",
              "      <th>G</th>\n",
              "      <th>GS</th>\n",
              "      <th>Wgs</th>\n",
              "      <th>Lgs</th>\n",
              "      <th>ND</th>\n",
              "      <th>Wchp</th>\n",
              "      <th>Ltuf</th>\n",
              "      <th>Wtm</th>\n",
              "      <th>Ltm</th>\n",
              "      <th>tmW-L%</th>\n",
              "      <th>Wlst</th>\n",
              "      <th>Lsv</th>\n",
              "      <th>CG</th>\n",
              "      <th>SHO</th>\n",
              "      <th>QS</th>\n",
              "      <th>QS%</th>\n",
              "      <th>GmScA</th>\n",
              "      <th>Best</th>\n",
              "      <th>Wrst</th>\n",
              "      <th>BQR</th>\n",
              "      <th>BQS</th>\n",
              "      <th>sDR</th>\n",
              "      <th>lDR</th>\n",
              "      <th>RS/GS</th>\n",
              "      <th>RS/IP</th>\n",
              "      <th>IP/GS</th>\n",
              "      <th>Pit/GS</th>\n",
              "      <th>&lt;80</th>\n",
              "      <th>80-99</th>\n",
              "      <th>100-119</th>\n",
              "      <th>≥120</th>\n",
              "      <th>Max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Tim Adleman</td>\n",
              "      <td>28</td>\n",
              "      <td>CIN</td>\n",
              "      <td>69.2</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>6.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.462</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>38%</td>\n",
              "      <td>51.4</td>\n",
              "      <td>65</td>\n",
              "      <td>40</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>4.8</td>\n",
              "      <td>5.2</td>\n",
              "      <td>5.4</td>\n",
              "      <td>85</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Andrew Albers</td>\n",
              "      <td>30</td>\n",
              "      <td>MIN</td>\n",
              "      <td>17.0</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0%</td>\n",
              "      <td>34.0</td>\n",
              "      <td>41</td>\n",
              "      <td>27</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6.4</td>\n",
              "      <td>14.1</td>\n",
              "      <td>3.3</td>\n",
              "      <td>73</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Matt Albers</td>\n",
              "      <td>33</td>\n",
              "      <td>CHW</td>\n",
              "      <td>51.1</td>\n",
              "      <td>58</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0%</td>\n",
              "      <td>53.0</td>\n",
              "      <td>53</td>\n",
              "      <td>53</td>\n",
              "      <td>24</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>25</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Raul Alcantara</td>\n",
              "      <td>23</td>\n",
              "      <td>OAK</td>\n",
              "      <td>22.1</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.200</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0%</td>\n",
              "      <td>40.2</td>\n",
              "      <td>54</td>\n",
              "      <td>22</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>4.2</td>\n",
              "      <td>4.3</td>\n",
              "      <td>4.5</td>\n",
              "      <td>76</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Brett Anderson</td>\n",
              "      <td>28</td>\n",
              "      <td>LAD</td>\n",
              "      <td>11.1</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.333</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0%</td>\n",
              "      <td>26.0</td>\n",
              "      <td>40</td>\n",
              "      <td>16</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3.8</td>\n",
              "      <td>0.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>53</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>72</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Rk            Name  Age   Tm    IP  ...  <80  80-99  100-119  ≥120  Max\n",
              "0   1     Tim Adleman   28  CIN  69.2  ...    4      8        1     0  101\n",
              "1   2   Andrew Albers   30  MIN  17.0  ...    1      1        0     0   88\n",
              "2   3     Matt Albers   33  CHW  51.1  ...    1      0        0     0   25\n",
              "3   4  Raul Alcantara   23  OAK  22.1  ...    3      1        1     0  104\n",
              "4   5  Brett Anderson   28  LAD  11.1  ...    3      0        0     0   72\n",
              "\n",
              "[5 rows x 37 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### _Adding the Target Column_\n",
        "Our target variable is whether or not a player was a Cy Young winner. This data was found in a separate table, and the information is merged into each year's stats as a one-hot encoded variable where 1 indicates a winner and 0 indicates a non-winner. "
      ],
      "metadata": {
        "id": "-8_Kh7KBJnNL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# adds a column indicating whether a player is a Cy Young Award winner\n",
        "def cy_winner_column(combined_df, year):\n",
        "    \n",
        "    # starts of CY winner column with all False\n",
        "    combined_df['CY_winner'] = 0\n",
        "    \n",
        "    # creates a list of the winners names\n",
        "    winner_list = [name for name in dfWinner[dfWinner['Year'] == year]['Name']]\n",
        "    \n",
        "    # finds those players in the combined_df and changes their 'CY_winner' value to 1\n",
        "    for name in winner_list:\n",
        "        combined_df.loc[combined_df['Name'] == name, 'CY_winner'] = 1\n",
        "    \n",
        "    return combined_df"
      ],
      "metadata": {
        "id": "Uaqz0-ZFJ6h2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# notice the added CY_winner column\n",
        "cy_winner_column(df2016, 2016).describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "SGand9CHJ6ZP",
        "outputId": "60393768-30ab-4dfd-c0dd-1b2778bdf6d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Rk</th>\n",
              "      <th>Age</th>\n",
              "      <th>IP</th>\n",
              "      <th>G</th>\n",
              "      <th>GS</th>\n",
              "      <th>Wgs</th>\n",
              "      <th>Lgs</th>\n",
              "      <th>ND</th>\n",
              "      <th>Wchp</th>\n",
              "      <th>Ltuf</th>\n",
              "      <th>Wtm</th>\n",
              "      <th>Ltm</th>\n",
              "      <th>tmW-L%</th>\n",
              "      <th>Wlst</th>\n",
              "      <th>Lsv</th>\n",
              "      <th>CG</th>\n",
              "      <th>SHO</th>\n",
              "      <th>QS</th>\n",
              "      <th>GmScA</th>\n",
              "      <th>Best</th>\n",
              "      <th>Wrst</th>\n",
              "      <th>BQR</th>\n",
              "      <th>BQS</th>\n",
              "      <th>sDR</th>\n",
              "      <th>lDR</th>\n",
              "      <th>RS/GS</th>\n",
              "      <th>RS/IP</th>\n",
              "      <th>IP/GS</th>\n",
              "      <th>Pit/GS</th>\n",
              "      <th>&lt;80</th>\n",
              "      <th>80-99</th>\n",
              "      <th>100-119</th>\n",
              "      <th>≥120</th>\n",
              "      <th>Max</th>\n",
              "      <th>CY_winner</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>275.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>274.000000</td>\n",
              "      <td>274.000000</td>\n",
              "      <td>273.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>274.000000</td>\n",
              "      <td>274.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>275.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>183.058182</td>\n",
              "      <td>27.050909</td>\n",
              "      <td>97.650182</td>\n",
              "      <td>21.152727</td>\n",
              "      <td>15.781818</td>\n",
              "      <td>5.352727</td>\n",
              "      <td>5.520000</td>\n",
              "      <td>4.909091</td>\n",
              "      <td>1.280000</td>\n",
              "      <td>1.294545</td>\n",
              "      <td>7.945255</td>\n",
              "      <td>7.890511</td>\n",
              "      <td>0.447985</td>\n",
              "      <td>1.421818</td>\n",
              "      <td>1.981818</td>\n",
              "      <td>0.276364</td>\n",
              "      <td>0.123636</td>\n",
              "      <td>7.469091</td>\n",
              "      <td>47.460000</td>\n",
              "      <td>68.698182</td>\n",
              "      <td>23.025455</td>\n",
              "      <td>10.370909</td>\n",
              "      <td>3.280000</td>\n",
              "      <td>0.221818</td>\n",
              "      <td>7.974545</td>\n",
              "      <td>4.391971</td>\n",
              "      <td>4.050365</td>\n",
              "      <td>5.178909</td>\n",
              "      <td>86.814545</td>\n",
              "      <td>2.312727</td>\n",
              "      <td>7.730909</td>\n",
              "      <td>5.661818</td>\n",
              "      <td>0.076364</td>\n",
              "      <td>102.487273</td>\n",
              "      <td>0.007273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>112.110397</td>\n",
              "      <td>3.726649</td>\n",
              "      <td>66.429129</td>\n",
              "      <td>12.381937</td>\n",
              "      <td>11.409899</td>\n",
              "      <td>5.339833</td>\n",
              "      <td>4.053763</td>\n",
              "      <td>3.653179</td>\n",
              "      <td>1.484027</td>\n",
              "      <td>1.539198</td>\n",
              "      <td>6.859174</td>\n",
              "      <td>5.571617</td>\n",
              "      <td>0.232993</td>\n",
              "      <td>1.601857</td>\n",
              "      <td>1.805213</td>\n",
              "      <td>0.771283</td>\n",
              "      <td>0.381107</td>\n",
              "      <td>7.316736</td>\n",
              "      <td>9.314501</td>\n",
              "      <td>16.442329</td>\n",
              "      <td>13.291623</td>\n",
              "      <td>6.649232</td>\n",
              "      <td>2.918254</td>\n",
              "      <td>0.465876</td>\n",
              "      <td>5.645495</td>\n",
              "      <td>1.309982</td>\n",
              "      <td>1.827592</td>\n",
              "      <td>0.984103</td>\n",
              "      <td>12.443088</td>\n",
              "      <td>1.681919</td>\n",
              "      <td>6.071979</td>\n",
              "      <td>6.612736</td>\n",
              "      <td>0.304446</td>\n",
              "      <td>16.845228</td>\n",
              "      <td>0.085125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-12.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>86.500000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>36.100000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.333000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>42.550000</td>\n",
              "      <td>61.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.800000</td>\n",
              "      <td>3.300000</td>\n",
              "      <td>4.700000</td>\n",
              "      <td>82.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>97.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>180.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>88.200000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>0.469000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>48.800000</td>\n",
              "      <td>71.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>4.400000</td>\n",
              "      <td>4.100000</td>\n",
              "      <td>5.400000</td>\n",
              "      <td>90.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>107.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>288.500000</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>158.100000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>0.586000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>53.550000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.800000</td>\n",
              "      <td>5.850000</td>\n",
              "      <td>94.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>114.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>368.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>230.000000</td>\n",
              "      <td>64.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>70.300000</td>\n",
              "      <td>98.000000</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>14.100000</td>\n",
              "      <td>7.100000</td>\n",
              "      <td>108.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>124.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Rk         Age          IP  ...        ≥120         Max   CY_winner\n",
              "count  275.000000  275.000000  275.000000  ...  275.000000  275.000000  275.000000\n",
              "mean   183.058182   27.050909   97.650182  ...    0.076364  102.487273    0.007273\n",
              "std    112.110397    3.726649   66.429129  ...    0.304446   16.845228    0.085125\n",
              "min      1.000000   19.000000    3.000000  ...    0.000000   25.000000    0.000000\n",
              "25%     86.500000   24.000000   36.100000  ...    0.000000   97.000000    0.000000\n",
              "50%    180.000000   26.000000   88.200000  ...    0.000000  107.000000    0.000000\n",
              "75%    288.500000   29.000000  158.100000  ...    0.000000  114.000000    0.000000\n",
              "max    368.000000   43.000000  230.000000  ...    3.000000  124.000000    1.000000\n",
              "\n",
              "[8 rows x 35 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### _Aggregating Stats from Multiple Tables_\n",
        "The single dataset for each year did not have some key features we wanted to use, so we merged each year's starting pitchers dataframe (df*year*) with the standard pitching data from the same year. The data was merged along the Name and Tm columns, increasing our number of features from 36 to 64.\n",
        "\n",
        "The merging function also addresses some other formatting issues, such as repeat columns and % signs that interfered with the machine learning tasks."
      ],
      "metadata": {
        "id": "-rGxV7FSKA3n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cleans and merges dataframes for a given year, adds Cy Young information\n",
        "def aggregate_stats_per_year(starters, standard, year):\n",
        "    \n",
        "    # formats names of players in both dfs\n",
        "    format_df_names(starters)\n",
        "    format_df_names(standard)\n",
        "    \n",
        "    # removes repeat columns from standard so there is no redundancy in merged df\n",
        "    repeat_columns = ['Rk', 'Age', 'IP', 'G', 'GS', 'CG','SHO']\n",
        "    standard_filtered = standard.drop(repeat_columns, axis = 1)\n",
        "\n",
        "    # merges df\n",
        "    merged_df = pd.merge(starters, standard_filtered, how=\"left\", on=['Name','Tm'])\n",
        "    \n",
        "    # adds a year column\n",
        "    merged_df[\"Year\"] = year\n",
        "    \n",
        "    # change string percent to float\n",
        "    merged_df['QS%'] = merged_df['QS%'].str.rstrip('%').astype('float') / 100.0\n",
        "\n",
        "    # adds the Cy Young Winner information\n",
        "    combined_df = cy_winner_column(merged_df, year)\n",
        "    \n",
        "    return combined_df"
      ],
      "metadata": {
        "id": "PThyCCG1J6Px"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_2016 = aggregate_stats_per_year(df2016, std2016, 2016)\n",
        "combined_2016.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "BNC3cFVQJ5_L",
        "outputId": "854cb294-9236-45c8-c160-566cb91f33ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Rk</th>\n",
              "      <th>Age</th>\n",
              "      <th>IP</th>\n",
              "      <th>G</th>\n",
              "      <th>GS</th>\n",
              "      <th>Wgs</th>\n",
              "      <th>Lgs</th>\n",
              "      <th>ND</th>\n",
              "      <th>Wchp</th>\n",
              "      <th>Ltuf</th>\n",
              "      <th>Wtm</th>\n",
              "      <th>Ltm</th>\n",
              "      <th>tmW-L%</th>\n",
              "      <th>Wlst</th>\n",
              "      <th>Lsv</th>\n",
              "      <th>CG</th>\n",
              "      <th>SHO</th>\n",
              "      <th>QS</th>\n",
              "      <th>QS%</th>\n",
              "      <th>GmScA</th>\n",
              "      <th>Best</th>\n",
              "      <th>Wrst</th>\n",
              "      <th>BQR</th>\n",
              "      <th>BQS</th>\n",
              "      <th>sDR</th>\n",
              "      <th>lDR</th>\n",
              "      <th>RS/GS</th>\n",
              "      <th>RS/IP</th>\n",
              "      <th>IP/GS</th>\n",
              "      <th>Pit/GS</th>\n",
              "      <th>&lt;80</th>\n",
              "      <th>80-99</th>\n",
              "      <th>100-119</th>\n",
              "      <th>≥120</th>\n",
              "      <th>Max</th>\n",
              "      <th>CY_winner</th>\n",
              "      <th>W</th>\n",
              "      <th>L</th>\n",
              "      <th>W-L%</th>\n",
              "      <th>ERA</th>\n",
              "      <th>GF</th>\n",
              "      <th>SV</th>\n",
              "      <th>H</th>\n",
              "      <th>R</th>\n",
              "      <th>ER</th>\n",
              "      <th>HR</th>\n",
              "      <th>BB</th>\n",
              "      <th>IBB</th>\n",
              "      <th>SO</th>\n",
              "      <th>HBP</th>\n",
              "      <th>BK</th>\n",
              "      <th>WP</th>\n",
              "      <th>BF</th>\n",
              "      <th>ERA+</th>\n",
              "      <th>FIP</th>\n",
              "      <th>WHIP</th>\n",
              "      <th>H9</th>\n",
              "      <th>HR9</th>\n",
              "      <th>BB9</th>\n",
              "      <th>SO9</th>\n",
              "      <th>SO/W</th>\n",
              "      <th>Year</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>275.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>274.000000</td>\n",
              "      <td>274.000000</td>\n",
              "      <td>273.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>274.000000</td>\n",
              "      <td>274.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>271.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>274.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>271.000000</td>\n",
              "      <td>275.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>183.058182</td>\n",
              "      <td>27.050909</td>\n",
              "      <td>97.650182</td>\n",
              "      <td>21.152727</td>\n",
              "      <td>15.781818</td>\n",
              "      <td>5.352727</td>\n",
              "      <td>5.520000</td>\n",
              "      <td>4.909091</td>\n",
              "      <td>1.280000</td>\n",
              "      <td>1.294545</td>\n",
              "      <td>7.945255</td>\n",
              "      <td>7.890511</td>\n",
              "      <td>0.447985</td>\n",
              "      <td>1.421818</td>\n",
              "      <td>1.981818</td>\n",
              "      <td>0.276364</td>\n",
              "      <td>0.123636</td>\n",
              "      <td>7.469091</td>\n",
              "      <td>0.350109</td>\n",
              "      <td>47.460000</td>\n",
              "      <td>68.698182</td>\n",
              "      <td>23.025455</td>\n",
              "      <td>10.370909</td>\n",
              "      <td>3.280000</td>\n",
              "      <td>0.221818</td>\n",
              "      <td>7.974545</td>\n",
              "      <td>4.391971</td>\n",
              "      <td>4.050365</td>\n",
              "      <td>5.178909</td>\n",
              "      <td>86.814545</td>\n",
              "      <td>2.312727</td>\n",
              "      <td>7.730909</td>\n",
              "      <td>5.661818</td>\n",
              "      <td>0.076364</td>\n",
              "      <td>102.487273</td>\n",
              "      <td>0.007273</td>\n",
              "      <td>5.774545</td>\n",
              "      <td>5.865455</td>\n",
              "      <td>0.430657</td>\n",
              "      <td>4.995818</td>\n",
              "      <td>1.567273</td>\n",
              "      <td>0.112727</td>\n",
              "      <td>97.727273</td>\n",
              "      <td>50.109091</td>\n",
              "      <td>46.472727</td>\n",
              "      <td>13.130909</td>\n",
              "      <td>31.829091</td>\n",
              "      <td>1.360000</td>\n",
              "      <td>84.680000</td>\n",
              "      <td>3.570909</td>\n",
              "      <td>0.338182</td>\n",
              "      <td>3.378182</td>\n",
              "      <td>416.614545</td>\n",
              "      <td>100.551095</td>\n",
              "      <td>4.694473</td>\n",
              "      <td>1.436658</td>\n",
              "      <td>9.703273</td>\n",
              "      <td>1.385091</td>\n",
              "      <td>3.235273</td>\n",
              "      <td>7.425455</td>\n",
              "      <td>2.651587</td>\n",
              "      <td>2016.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>112.110397</td>\n",
              "      <td>3.726649</td>\n",
              "      <td>66.429129</td>\n",
              "      <td>12.381937</td>\n",
              "      <td>11.409899</td>\n",
              "      <td>5.339833</td>\n",
              "      <td>4.053763</td>\n",
              "      <td>3.653179</td>\n",
              "      <td>1.484027</td>\n",
              "      <td>1.539198</td>\n",
              "      <td>6.859174</td>\n",
              "      <td>5.571617</td>\n",
              "      <td>0.232993</td>\n",
              "      <td>1.601857</td>\n",
              "      <td>1.805213</td>\n",
              "      <td>0.771283</td>\n",
              "      <td>0.381107</td>\n",
              "      <td>7.316736</td>\n",
              "      <td>0.236057</td>\n",
              "      <td>9.314501</td>\n",
              "      <td>16.442329</td>\n",
              "      <td>13.291623</td>\n",
              "      <td>6.649232</td>\n",
              "      <td>2.918254</td>\n",
              "      <td>0.465876</td>\n",
              "      <td>5.645495</td>\n",
              "      <td>1.309982</td>\n",
              "      <td>1.827592</td>\n",
              "      <td>0.984103</td>\n",
              "      <td>12.443088</td>\n",
              "      <td>1.681919</td>\n",
              "      <td>6.071979</td>\n",
              "      <td>6.612736</td>\n",
              "      <td>0.304446</td>\n",
              "      <td>16.845228</td>\n",
              "      <td>0.085125</td>\n",
              "      <td>5.156677</td>\n",
              "      <td>3.939331</td>\n",
              "      <td>0.237108</td>\n",
              "      <td>2.497790</td>\n",
              "      <td>3.093144</td>\n",
              "      <td>0.524945</td>\n",
              "      <td>62.197782</td>\n",
              "      <td>30.585332</td>\n",
              "      <td>28.475021</td>\n",
              "      <td>8.774816</td>\n",
              "      <td>20.886639</td>\n",
              "      <td>1.520373</td>\n",
              "      <td>64.042978</td>\n",
              "      <td>3.123590</td>\n",
              "      <td>0.666040</td>\n",
              "      <td>3.273801</td>\n",
              "      <td>273.695747</td>\n",
              "      <td>46.219645</td>\n",
              "      <td>1.486279</td>\n",
              "      <td>0.357688</td>\n",
              "      <td>2.673339</td>\n",
              "      <td>0.828879</td>\n",
              "      <td>1.370343</td>\n",
              "      <td>1.839948</td>\n",
              "      <td>1.380778</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-12.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>1.800000</td>\n",
              "      <td>0.545000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.600000</td>\n",
              "      <td>0.330000</td>\n",
              "      <td>2016.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>86.500000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>36.100000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.333000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.170000</td>\n",
              "      <td>42.550000</td>\n",
              "      <td>61.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.800000</td>\n",
              "      <td>3.300000</td>\n",
              "      <td>4.700000</td>\n",
              "      <td>82.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>97.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.317000</td>\n",
              "      <td>3.605000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>39.500000</td>\n",
              "      <td>22.500000</td>\n",
              "      <td>20.500000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>166.500000</td>\n",
              "      <td>73.000000</td>\n",
              "      <td>3.780000</td>\n",
              "      <td>1.223000</td>\n",
              "      <td>8.250000</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>2.300000</td>\n",
              "      <td>6.300000</td>\n",
              "      <td>1.850000</td>\n",
              "      <td>2016.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>180.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>88.200000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>0.469000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.380000</td>\n",
              "      <td>48.800000</td>\n",
              "      <td>71.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>4.400000</td>\n",
              "      <td>4.100000</td>\n",
              "      <td>5.400000</td>\n",
              "      <td>90.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>107.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.444000</td>\n",
              "      <td>4.570000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>90.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>45.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>378.000000</td>\n",
              "      <td>92.500000</td>\n",
              "      <td>4.480000</td>\n",
              "      <td>1.375000</td>\n",
              "      <td>9.300000</td>\n",
              "      <td>1.200000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>7.500000</td>\n",
              "      <td>2.400000</td>\n",
              "      <td>2016.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>288.500000</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>158.100000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>0.586000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>0.530000</td>\n",
              "      <td>53.550000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.800000</td>\n",
              "      <td>5.850000</td>\n",
              "      <td>94.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>114.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>0.579000</td>\n",
              "      <td>5.805000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>154.000000</td>\n",
              "      <td>75.000000</td>\n",
              "      <td>69.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>46.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>134.000000</td>\n",
              "      <td>5.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>668.500000</td>\n",
              "      <td>117.000000</td>\n",
              "      <td>5.195000</td>\n",
              "      <td>1.567500</td>\n",
              "      <td>10.550000</td>\n",
              "      <td>1.700000</td>\n",
              "      <td>3.900000</td>\n",
              "      <td>8.600000</td>\n",
              "      <td>3.280000</td>\n",
              "      <td>2016.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>368.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>230.000000</td>\n",
              "      <td>64.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>70.300000</td>\n",
              "      <td>98.000000</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>14.100000</td>\n",
              "      <td>7.100000</td>\n",
              "      <td>108.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>124.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>227.000000</td>\n",
              "      <td>124.000000</td>\n",
              "      <td>113.000000</td>\n",
              "      <td>37.000000</td>\n",
              "      <td>86.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>284.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>951.000000</td>\n",
              "      <td>387.000000</td>\n",
              "      <td>12.900000</td>\n",
              "      <td>3.563000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>6.800000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>12.500000</td>\n",
              "      <td>15.640000</td>\n",
              "      <td>2016.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Rk         Age          IP  ...         SO9        SO/W    Year\n",
              "count  275.000000  275.000000  275.000000  ...  275.000000  271.000000   275.0\n",
              "mean   183.058182   27.050909   97.650182  ...    7.425455    2.651587  2016.0\n",
              "std    112.110397    3.726649   66.429129  ...    1.839948    1.380778     0.0\n",
              "min      1.000000   19.000000    3.000000  ...    2.600000    0.330000  2016.0\n",
              "25%     86.500000   24.000000   36.100000  ...    6.300000    1.850000  2016.0\n",
              "50%    180.000000   26.000000   88.200000  ...    7.500000    2.400000  2016.0\n",
              "75%    288.500000   29.000000  158.100000  ...    8.600000    3.280000  2016.0\n",
              "max    368.000000   43.000000  230.000000  ...   12.500000   15.640000  2016.0\n",
              "\n",
              "[8 rows x 62 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### _Combining Data Across the Years_\n",
        "Each year's data is cleaned as outlined above. Then all of the processed years were merged into one dataframe to use for machine learning. We also determined a set of features to remove from the dataset that we felt were not useful metrics for overall pitcher performance."
      ],
      "metadata": {
        "id": "WSt1LDkMKYQa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# apply to the rest of the years\n",
        "combined_2017 = aggregate_stats_per_year(df2017, std2017, 2017)\n",
        "\n",
        "combined_2018 = aggregate_stats_per_year(df2018, std2018, 2018)\n",
        "\n",
        "combined_2019 = aggregate_stats_per_year(df2019, std2019, 2019)\n",
        "\n",
        "combined_2021 = aggregate_stats_per_year(df2021, std2021, 2021)"
      ],
      "metadata": {
        "id": "PGSGwJD7KYo7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# list of training data\n",
        "all_data = [combined_2016, combined_2017, combined_2018, combined_2019]\n",
        "\n",
        "# merging all dataframes\n",
        "all_data_df = pd.concat(all_data)\n",
        "\n",
        "# getting rid of rows with NaN\n",
        "df_merged = all_data_df.dropna()\n",
        "\n",
        "# get rid of discussed columns to reduce features\n",
        "df_merged = df_merged.drop([\"G\", \"CG\", \"SHO\", \"Best\", \"Wrst\", \"BQR\", \"BQS\", \"sDR\", \"lDR\", \n",
        "                            \"RS/IP\", \"<80\", \"80-99\", \"100-119\", \"≥120\", \"Max\"], axis = 1)\n",
        "\n",
        "df_merged"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        },
        "id": "wX8A7VfpKYen",
        "outputId": "9be5a3dc-e122-4f97-adbe-b0140451267d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Rk</th>\n",
              "      <th>Name</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tm</th>\n",
              "      <th>IP</th>\n",
              "      <th>GS</th>\n",
              "      <th>Wgs</th>\n",
              "      <th>Lgs</th>\n",
              "      <th>ND</th>\n",
              "      <th>Wchp</th>\n",
              "      <th>Ltuf</th>\n",
              "      <th>Wtm</th>\n",
              "      <th>Ltm</th>\n",
              "      <th>tmW-L%</th>\n",
              "      <th>Wlst</th>\n",
              "      <th>Lsv</th>\n",
              "      <th>QS</th>\n",
              "      <th>QS%</th>\n",
              "      <th>GmScA</th>\n",
              "      <th>RS/GS</th>\n",
              "      <th>IP/GS</th>\n",
              "      <th>Pit/GS</th>\n",
              "      <th>CY_winner</th>\n",
              "      <th>Lg</th>\n",
              "      <th>W</th>\n",
              "      <th>L</th>\n",
              "      <th>W-L%</th>\n",
              "      <th>ERA</th>\n",
              "      <th>GF</th>\n",
              "      <th>SV</th>\n",
              "      <th>H</th>\n",
              "      <th>R</th>\n",
              "      <th>ER</th>\n",
              "      <th>HR</th>\n",
              "      <th>BB</th>\n",
              "      <th>IBB</th>\n",
              "      <th>SO</th>\n",
              "      <th>HBP</th>\n",
              "      <th>BK</th>\n",
              "      <th>WP</th>\n",
              "      <th>BF</th>\n",
              "      <th>ERA+</th>\n",
              "      <th>FIP</th>\n",
              "      <th>WHIP</th>\n",
              "      <th>H9</th>\n",
              "      <th>HR9</th>\n",
              "      <th>BB9</th>\n",
              "      <th>SO9</th>\n",
              "      <th>SO/W</th>\n",
              "      <th>Year</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Tim Adleman</td>\n",
              "      <td>28</td>\n",
              "      <td>CIN</td>\n",
              "      <td>69.2</td>\n",
              "      <td>13</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>6.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.462</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>0.38</td>\n",
              "      <td>51.4</td>\n",
              "      <td>4.8</td>\n",
              "      <td>5.4</td>\n",
              "      <td>85</td>\n",
              "      <td>0</td>\n",
              "      <td>NL</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.500</td>\n",
              "      <td>4.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>287.0</td>\n",
              "      <td>107.0</td>\n",
              "      <td>5.30</td>\n",
              "      <td>1.206</td>\n",
              "      <td>8.3</td>\n",
              "      <td>1.7</td>\n",
              "      <td>2.6</td>\n",
              "      <td>6.1</td>\n",
              "      <td>2.35</td>\n",
              "      <td>2016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Matt Albers</td>\n",
              "      <td>33</td>\n",
              "      <td>CHW</td>\n",
              "      <td>51.1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>53.0</td>\n",
              "      <td>4.2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>25</td>\n",
              "      <td>0</td>\n",
              "      <td>AL</td>\n",
              "      <td>2.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.250</td>\n",
              "      <td>6.31</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>237.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>5.80</td>\n",
              "      <td>1.675</td>\n",
              "      <td>11.7</td>\n",
              "      <td>1.8</td>\n",
              "      <td>3.3</td>\n",
              "      <td>5.3</td>\n",
              "      <td>1.58</td>\n",
              "      <td>2016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Raul Alcantara</td>\n",
              "      <td>23</td>\n",
              "      <td>OAK</td>\n",
              "      <td>22.1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.200</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>40.2</td>\n",
              "      <td>4.2</td>\n",
              "      <td>4.5</td>\n",
              "      <td>76</td>\n",
              "      <td>0</td>\n",
              "      <td>AL</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.250</td>\n",
              "      <td>7.25</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>103.0</td>\n",
              "      <td>57.0</td>\n",
              "      <td>8.21</td>\n",
              "      <td>1.567</td>\n",
              "      <td>12.5</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.6</td>\n",
              "      <td>5.6</td>\n",
              "      <td>3.50</td>\n",
              "      <td>2016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Brett Anderson</td>\n",
              "      <td>28</td>\n",
              "      <td>LAD</td>\n",
              "      <td>11.1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.333</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>26.0</td>\n",
              "      <td>3.8</td>\n",
              "      <td>3.0</td>\n",
              "      <td>53</td>\n",
              "      <td>0</td>\n",
              "      <td>NL</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.333</td>\n",
              "      <td>11.91</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>7.91</td>\n",
              "      <td>2.559</td>\n",
              "      <td>19.9</td>\n",
              "      <td>3.2</td>\n",
              "      <td>3.2</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.25</td>\n",
              "      <td>2016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>Chase Anderson</td>\n",
              "      <td>28</td>\n",
              "      <td>MIL</td>\n",
              "      <td>151.2</td>\n",
              "      <td>30</td>\n",
              "      <td>9</td>\n",
              "      <td>11</td>\n",
              "      <td>10</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>12.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>0.400</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>0.20</td>\n",
              "      <td>48.8</td>\n",
              "      <td>4.7</td>\n",
              "      <td>5.0</td>\n",
              "      <td>87</td>\n",
              "      <td>0</td>\n",
              "      <td>NL</td>\n",
              "      <td>9.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.450</td>\n",
              "      <td>4.39</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>155.0</td>\n",
              "      <td>83.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>647.0</td>\n",
              "      <td>97.0</td>\n",
              "      <td>5.09</td>\n",
              "      <td>1.371</td>\n",
              "      <td>9.2</td>\n",
              "      <td>1.7</td>\n",
              "      <td>3.1</td>\n",
              "      <td>7.1</td>\n",
              "      <td>2.26</td>\n",
              "      <td>2016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>322</th>\n",
              "      <td>426</td>\n",
              "      <td>Ryan Yarbrough</td>\n",
              "      <td>27</td>\n",
              "      <td>TBR</td>\n",
              "      <td>141.2</td>\n",
              "      <td>14</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.500</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>0.50</td>\n",
              "      <td>54.2</td>\n",
              "      <td>4.0</td>\n",
              "      <td>6.1</td>\n",
              "      <td>88</td>\n",
              "      <td>0</td>\n",
              "      <td>AL</td>\n",
              "      <td>11.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.647</td>\n",
              "      <td>4.13</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>121.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>563.0</td>\n",
              "      <td>106.0</td>\n",
              "      <td>3.55</td>\n",
              "      <td>0.995</td>\n",
              "      <td>7.7</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.3</td>\n",
              "      <td>7.4</td>\n",
              "      <td>5.85</td>\n",
              "      <td>2019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>323</th>\n",
              "      <td>427</td>\n",
              "      <td>Gabriel Ynoa</td>\n",
              "      <td>26</td>\n",
              "      <td>BAL</td>\n",
              "      <td>110.2</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0.077</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0.23</td>\n",
              "      <td>42.9</td>\n",
              "      <td>2.8</td>\n",
              "      <td>4.9</td>\n",
              "      <td>80</td>\n",
              "      <td>0</td>\n",
              "      <td>AL</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.091</td>\n",
              "      <td>5.61</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>126.0</td>\n",
              "      <td>77.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>480.0</td>\n",
              "      <td>84.0</td>\n",
              "      <td>6.20</td>\n",
              "      <td>1.373</td>\n",
              "      <td>10.2</td>\n",
              "      <td>2.4</td>\n",
              "      <td>2.1</td>\n",
              "      <td>5.4</td>\n",
              "      <td>2.58</td>\n",
              "      <td>2019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>324</th>\n",
              "      <td>428</td>\n",
              "      <td>Alex Young</td>\n",
              "      <td>25</td>\n",
              "      <td>ARI</td>\n",
              "      <td>83.1</td>\n",
              "      <td>15</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.467</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0.33</td>\n",
              "      <td>51.8</td>\n",
              "      <td>4.3</td>\n",
              "      <td>5.1</td>\n",
              "      <td>84</td>\n",
              "      <td>0</td>\n",
              "      <td>NL</td>\n",
              "      <td>7.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.583</td>\n",
              "      <td>3.56</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>349.0</td>\n",
              "      <td>125.0</td>\n",
              "      <td>4.81</td>\n",
              "      <td>1.188</td>\n",
              "      <td>7.8</td>\n",
              "      <td>1.5</td>\n",
              "      <td>2.9</td>\n",
              "      <td>7.7</td>\n",
              "      <td>2.63</td>\n",
              "      <td>2019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>325</th>\n",
              "      <td>429</td>\n",
              "      <td>T.J. Zeuch</td>\n",
              "      <td>23</td>\n",
              "      <td>TOR</td>\n",
              "      <td>22.2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.333</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>45.7</td>\n",
              "      <td>2.8</td>\n",
              "      <td>4.4</td>\n",
              "      <td>81</td>\n",
              "      <td>0</td>\n",
              "      <td>AL</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.333</td>\n",
              "      <td>4.76</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>4.05</td>\n",
              "      <td>1.456</td>\n",
              "      <td>8.7</td>\n",
              "      <td>0.8</td>\n",
              "      <td>4.4</td>\n",
              "      <td>7.9</td>\n",
              "      <td>1.82</td>\n",
              "      <td>2019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>326</th>\n",
              "      <td>430</td>\n",
              "      <td>Jordan Zimmermann</td>\n",
              "      <td>33</td>\n",
              "      <td>DET</td>\n",
              "      <td>112.0</td>\n",
              "      <td>23</td>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0.174</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>0.22</td>\n",
              "      <td>41.1</td>\n",
              "      <td>3.2</td>\n",
              "      <td>4.9</td>\n",
              "      <td>81</td>\n",
              "      <td>0</td>\n",
              "      <td>AL</td>\n",
              "      <td>1.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>0.071</td>\n",
              "      <td>6.91</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>145.0</td>\n",
              "      <td>89.0</td>\n",
              "      <td>86.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>504.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>4.79</td>\n",
              "      <td>1.518</td>\n",
              "      <td>11.7</td>\n",
              "      <td>1.5</td>\n",
              "      <td>2.0</td>\n",
              "      <td>6.6</td>\n",
              "      <td>3.28</td>\n",
              "      <td>2019</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1156 rows × 50 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Rk               Name  Age   Tm     IP  ...  HR9  BB9  SO9  SO/W  Year\n",
              "0      1        Tim Adleman   28  CIN   69.2  ...  1.7  2.6  6.1  2.35  2016\n",
              "2      3        Matt Albers   33  CHW   51.1  ...  1.8  3.3  5.3  1.58  2016\n",
              "3      4     Raul Alcantara   23  OAK   22.1  ...  3.6  1.6  5.6  3.50  2016\n",
              "4      5     Brett Anderson   28  LAD   11.1  ...  3.2  3.2  4.0  1.25  2016\n",
              "5      6     Chase Anderson   28  MIL  151.2  ...  1.7  3.1  7.1  2.26  2016\n",
              "..   ...                ...  ...  ...    ...  ...  ...  ...  ...   ...   ...\n",
              "322  426     Ryan Yarbrough   27  TBR  141.2  ...  1.0  1.3  7.4  5.85  2019\n",
              "323  427       Gabriel Ynoa   26  BAL  110.2  ...  2.4  2.1  5.4  2.58  2019\n",
              "324  428         Alex Young   25  ARI   83.1  ...  1.5  2.9  7.7  2.63  2019\n",
              "325  429         T.J. Zeuch   23  TOR   22.2  ...  0.8  4.4  7.9  1.82  2019\n",
              "326  430  Jordan Zimmermann   33  DET  112.0  ...  1.5  2.0  6.6  3.28  2019\n",
              "\n",
              "[1156 rows x 50 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### _Scaling and Transformation, Splitting_\n",
        "Our dataset is very imbalanced, as less than 1% of players are winners of the Cy Young award. To help address this, we used cross validation and repetion of training to more accuratly assess our machine learning model. Therefore, scaling and splitting is performed later in this report to avoid leaking test data to the model during training from resampling."
      ],
      "metadata": {
        "id": "odDWrpw0NCJT"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E38DvXzLDaBK"
      },
      "source": [
        "### 3.2. Data Exploration\n",
        "These visualizations characcterize our dataset. They show the size disparity of the target classes, and some possibly important metrics to quantify pitcher performance over a season.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://i.ibb.co/nsVGn2W/winners-pie-plot.png\" alt=\"winners-pie-plot\" border=\"0\">"
      ],
      "metadata": {
        "id": "Aw5VzELsTZlZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This pie chart shows how few winners there are compared to the entire population of pitchers. It demonstrates how unbalanced the target variables (classes) are."
      ],
      "metadata": {
        "id": "XWwygV5YTeqx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://i.ibb.co/pXrfTCf/ERA-bar-chart.png\" alt=\"ERA-bar-chart\" border=\"0\">"
      ],
      "metadata": {
        "id": "X1CrnP0sTOIi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This bar chart shows the ERA (earned run average), which is the average number of runs a pitcher allows per 9 innings. It splits the data up by year, and by winners vs non-winners. This was done to show how there is a visible difference between the average ERA of the winners and non-winners for every year."
      ],
      "metadata": {
        "id": "O4yLBFEnThc4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://i.ibb.co/FhFtB7v/wins-violin-plot.png\" alt=\"wins-violin-plot\" border=\"0\">"
      ],
      "metadata": {
        "id": "8andoOpQTQ6G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This violin plot shows the average number of wins for winners and non-winners. The Cy Young winners data is represented by a 1, and the non-winners data is represented by a 0. While their ranges do overlap relatively significantly, this visualization shows that winners on average clearly have a higher number of wins than non-winners."
      ],
      "metadata": {
        "id": "uD9JHbZETkEM"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P232mnZ7DaBK"
      },
      "source": [
        "### 3.3. Model Training\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### _Splitting The Dataset_\n",
        "Due to the imbalanced nature of our dataset, we use cross validation to build our model. To avoid leaking the testing data values during training, we use percentage split to divide the dataset into a training set and a testing set, where we then split into features and targets, etc."
      ],
      "metadata": {
        "id": "rjWrWb-C_6ZT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# splitting data into features and target\n",
        "def features_and_target(df):\n",
        "    features = df.drop([\"CY_winner\", \"Name\", \"Tm\", \"Year\", \"Lg\"], axis = 1)\n",
        "    target = df[\"CY_winner\"]\n",
        "    return(features, target)"
      ],
      "metadata": {
        "id": "NEcfhEEXabhi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def split_the_dataset(features, target):    \n",
        "    X_train, X_test, y_train, y_test = train_test_split(features, target, random_state = 3000)\n",
        "    return(X_train, X_test, y_train, y_test)"
      ],
      "metadata": {
        "id": "Fycihhxyag4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split into training and testing dfs\n",
        "training_df, testing_df = train_test_split(df_merged, train_size = 0.75, random_state = 3000)"
      ],
      "metadata": {
        "id": "iXPNUEd08414"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For model development, we will only use *training_df*. \n",
        "\n",
        "For model evaluation (3.5), we will use *testing_df*."
      ],
      "metadata": {
        "id": "UJqwD6Xo88Xk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# our classifier models\n",
        "estimators = {\"LinearSVC\" : LinearSVC(max_iter=1000000), \n",
        "              \"Decision Tree\" : DecisionTreeClassifier(), \n",
        "              \"kNN\" : KNeighborsClassifier(),\n",
        "              \"Logistic Regression\" : LogisticRegression()}"
      ],
      "metadata": {
        "id": "UWc6RSOLaYbM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split the dataset into features and target\n",
        "train_features, train_target = features_and_target(training_df)\n",
        "\n",
        "# split into training and testing data\n",
        "X_train, X_test, y_train, y_test = split_the_dataset(train_features, train_target)"
      ],
      "metadata": {
        "id": "n63huB539FJw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### _Single Partition of the Data_\n",
        "Using only one split of the data, we noticed that there was a lot of variation in the accuracy metrics."
      ],
      "metadata": {
        "id": "X43cvAcRaLw1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "\n",
        "def preprocessed_classifier():\n",
        "    scaler = StandardScaler()\n",
        "\n",
        "    # preprocess/normalize data\n",
        "    scaler.fit(X_train) \n",
        "\n",
        "    # scale X data\n",
        "    X_train_scaled = scaler.transform(X_train) \n",
        "    X_test_scaled = scaler.transform(X_test) \n",
        "    \n",
        "    # itereate through classifier models\n",
        "    for estimator_name, estimator_object in estimators.items():\n",
        "\n",
        "        # create model on scaled data\n",
        "        clf = estimator_object.fit(X=X_train_scaled, y=y_train)\n",
        "\n",
        "        #make predictions on the training set\n",
        "        predicted = estimator_object.predict(X=X_train)\n",
        "\n",
        "        expected = y_train\n",
        "\n",
        "        #prediction accuracy\n",
        "        print(f\"{estimator_name}:\")\n",
        "        print(\"\\tPrediction accuracy on the training data:\", format(clf.score(X_train, y_train)*100, \".2f\"))\n",
        "        print(\"\\tPrediction accuracy on the test data:\", format(clf.score(X_test, y_test)*100, \".2f\"))\n",
        "        \n",
        "        # balanced accuracy score \n",
        "        balanced_accuracy = balanced_accuracy_score(expected, predicted)\n",
        "        print(\"\\tBalanced accuracy score:\",  format(balanced_accuracy * 100, \".2f\"), \"\\n\")\n",
        "    \n",
        "    return(X_train_scaled, X_test_scaled)"
      ],
      "metadata": {
        "id": "CvrG9tLtaoH7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test each model's performance\n",
        "X_train_scaled, X_test_scaled = preprocessed_classifier()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOeZzstPatK-",
        "outputId": "b43dd942-b722-4f2a-c506-50d6c67f0bae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LinearSVC:\n",
            "\tPrediction accuracy on the training data: 0.62\n",
            "\tPrediction accuracy on the test data: 0.92\n",
            "\tBalanced accuracy score: 50.00 \n",
            "\n",
            "Decision Tree:\n",
            "\tPrediction accuracy on the training data: 99.23\n",
            "\tPrediction accuracy on the test data: 99.08\n",
            "\tBalanced accuracy score: 49.92 \n",
            "\n",
            "kNN:\n",
            "\tPrediction accuracy on the training data: 92.46\n",
            "\tPrediction accuracy on the test data: 91.71\n",
            "\tBalanced accuracy score: 46.52 \n",
            "\n",
            "Logistic Regression:\n",
            "\tPrediction accuracy on the training data: 0.62\n",
            "\tPrediction accuracy on the test data: 0.92\n",
            "\tBalanced accuracy score: 50.00 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_scaled, X_test_scaled = preprocessed_classifier()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Hsrs0iM9xnz",
        "outputId": "c7096eab-b6e6-4bdb-a300-24512f51f39f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LinearSVC:\n",
            "\tPrediction accuracy on the training data: 0.62\n",
            "\tPrediction accuracy on the test data: 0.92\n",
            "\tBalanced accuracy score: 50.00 \n",
            "\n",
            "Decision Tree:\n",
            "\tPrediction accuracy on the training data: 1.23\n",
            "\tPrediction accuracy on the test data: 1.84\n",
            "\tBalanced accuracy score: 50.31 \n",
            "\n",
            "kNN:\n",
            "\tPrediction accuracy on the training data: 92.46\n",
            "\tPrediction accuracy on the test data: 91.71\n",
            "\tBalanced accuracy score: 46.52 \n",
            "\n",
            "Logistic Regression:\n",
            "\tPrediction accuracy on the training data: 0.62\n",
            "\tPrediction accuracy on the test data: 0.92\n",
            "\tBalanced accuracy score: 50.00 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each time we ran this code, the results would vary greatly and it was not obvious which model was best. Prediction accuracy values fluctuated between 1% and 99%, due to the imbalanced nature of our dataset: if a model correctly classified most of the non winners but none of the winners, the accuracy would be 99% without any true positives. To address this, a balanced accuracy score was also used to quantify model accuracy. This value is close to 50% for all models, indicating that the models are essentially randomly choosing how to classify players. These models were underfitting the data."
      ],
      "metadata": {
        "id": "YkUloZmGay-n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### _Cross Validation and Resampling_\n",
        "Due to the inconsistent results above, we changed our approach to use cross validation and resampling of our dataset. Both of these methods increase accuracy because the model has more data to train with. From the random resamples, an average accuracy score is returned. This is much more stable than the values we were getting using the previous approach, and are more representative of the true accuracy of the models."
      ],
      "metadata": {
        "id": "sElobBndbRTm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import numpy\n",
        "\n",
        "# cross validation and resampling\n",
        "def classifiers_cross_validation(df):\n",
        "        \n",
        "    # iterate through dictionary of different methods, change the estimator each time\n",
        "    for estimator_name, estimator_object in estimators.items():\n",
        "        \n",
        "        # pipeline of scaler and classifier (need to scale and split each time, or else leaking data)\n",
        "        clf = make_pipeline(StandardScaler(), estimator_object)\n",
        "        \n",
        "        # noticed accuracies were very variable and sensitive -> run many times and take average\n",
        "        all_scores = []\n",
        "        for n in range(100):\n",
        "            \n",
        "            # resample the dataframe for each run\n",
        "            df_resample = df.sample(frac=1.0, replace=1)\n",
        "            \n",
        "            # get features and target dfs\n",
        "            features, target = features_and_target(df_resample)\n",
        "            \n",
        "            # run 5-fold CV to train and test model\n",
        "            scores = cross_val_score(estimator=clf, X=features, y=target, cv=5, scoring='balanced_accuracy')\n",
        "            \n",
        "            all_scores.extend(scores)\n",
        "            \n",
        "        print(f\"{estimator_name}:\") \n",
        "        # print average of accuracy scores\n",
        "        print(f\"\\tBalanced accuracy mean = {numpy.nanmean(all_scores):.2%}\")\n",
        "        print(f\"\\tBalanced accuracy std = {numpy.nanstd(all_scores):.2%}\")"
      ],
      "metadata": {
        "id": "9L2gslBUb9dh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "classifiers_cross_validation(training_df)"
      ],
      "metadata": {
        "id": "OkAILjDCaysa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From these balanced accuracy averages, decision trees was the best model as it had the highest accuracy value of the four models tested. The baseline decision trees function to tune is below."
      ],
      "metadata": {
        "id": "29CrXFaDeCn2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cross validation and resampling for selected model (use for tuning)\n",
        "def classifier_cv(df, model):\n",
        "        \n",
        "    # pipeline of scaler and classifier (need to scale and split each time, or else leaking data)\n",
        "    clf = make_pipeline(StandardScaler(), model)\n",
        "        \n",
        "    # noticed accuracies were very variable and sensitive -> run many times and take average\n",
        "    all_scores = []\n",
        "    for n in range(100):\n",
        "            \n",
        "        # resample the dataframe for each run\n",
        "        df_resample = df.sample(frac=1.0, replace=1)\n",
        "            \n",
        "        # get features and target dfs\n",
        "        features, target = features_and_target(df_resample)\n",
        "            \n",
        "        # run 5-fold CV to train and test model\n",
        "        scores = cross_val_score(estimator=clf, X=features, y=target, cv=5, scoring='balanced_accuracy')\n",
        "            \n",
        "        all_scores.extend(scores)\n",
        "        \n",
        "    # print average accuracy scores\n",
        "    print(f\"\\tbalanced accuracy mean = {numpy.nanmean(all_scores):.2%}\")\n",
        "    print(f\"\\tbalanced accuracy std = {numpy.nanstd(all_scores):.2%}\")"
      ],
      "metadata": {
        "id": "ZJAEUz3TlOmX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### _Feature Selection_\n",
        "Our dataset has about 50 features, so determining a subset that will yield the similar results is useful. We used iterative feature selection to select the most representative features.\n",
        "\n",
        "Though accuracy scores were determined over many samples and splits of our dataset, feature selection will be determined based on one random split only."
      ],
      "metadata": {
        "id": "QuJ0lAe8ev64"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# scale the split a single partition of the data to use for feature selection\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train) \n",
        "\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "9u31Fav4fLhR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "def RFE_feature_selection():\n",
        "    \n",
        "    # RFE selector, fit to the training data\n",
        "    select = RFE(DecisionTreeRegressor(random_state = 3000), n_features_to_select = 20)\n",
        "    select.fit(X_train_scaled, y_train)\n",
        "    \n",
        "    # transform training and testing sets so only the selected features are retained\n",
        "    X_train_selected = select.transform(X_train_scaled)\n",
        "    X_test_selected = select.transform(X_test_scaled)\n",
        "\n",
        "    # determine selected features on the model    \n",
        "    model = DecisionTreeClassifier().fit(X=X_train_selected, y=y_train)\n",
        "    \n",
        "    # print selected features and make them into a list\n",
        "    print(\"Selected features after RFE:\")\n",
        "    selected_features = []\n",
        "    for i in range(len(train_features.columns)):\n",
        "        if select.support_[i] == True:\n",
        "            selected_features.append(train_features.columns[i])\n",
        "            print(\"\\t\", train_features.columns[i], sep=\"\")\n",
        "    \n",
        "    return(X_train_selected, X_test_selected, selected_features)"
      ],
      "metadata": {
        "id": "qYZ377-Qf6q7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_selected, X_test_selected, selected_features = RFE_feature_selection()"
      ],
      "metadata": {
        "id": "Yw7tlsqif6kK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id_columns = [\"CY_winner\", \"Name\", \"Tm\", \"Year\", \"Lg\"]\n",
        "selected_features.extend(id_columns)\n",
        "\n",
        "# isolate the selected features\n",
        "df_selected = df_merged[selected_features]\n",
        "\n",
        "# classify based with the selected features\n",
        "classifier_cv(df_selected, DecisionTreeClassifier())"
      ],
      "metadata": {
        "id": "RilzYKcUjnHU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vij89twYDaBK"
      },
      "source": [
        "### 3.4. Model Optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### _Hyperparameter Tuning_\n",
        "For our model, DecisionTreeClassifier, we chose to tune the following parameters:\n",
        "* criterion: the function to measure the quality of a split\n",
        "* max_depth: the maximum depth of the tree\n",
        "* class_weight: relative weights of the target class\n",
        "\n",
        "We are tuning our model to avoid overfitting to the training data. Especially since this dataset is small, placing more restrictions on our model will likely make it more generalizable to new data. In addition, since it is imbalanced, the class_weight parameter will likely halp even out the two target classes."
      ],
      "metadata": {
        "id": "hd9WyQdpiShD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {'criterion':['gini', 'entropy'], \n",
        "              'class_weight':['', 'balanced'],\n",
        "              'max_depth':[5, 10, 15, 20, 30, 40],}"
      ],
      "metadata": {
        "id": "TPRtjvYMiTKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similarly to our model training, we noticed that each time we ran our hyperparameter tuning function, the output would be different. Here, we run the function 10 times with resampling, and chose the values that appeared most often to evaluate performance."
      ],
      "metadata": {
        "id": "b99zdORqisk-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# noticed the best parameters changed each time -> run a bunch of times\n",
        "for n in range(10):\n",
        "    \n",
        "    # resample the dataframe each time\n",
        "    df_resample = df_merged.sample(frac=1.0, replace=1)\n",
        "    \n",
        "    # get features and target dfs\n",
        "    features, target = features_and_target(df_resample)\n",
        "    \n",
        "    grid_search = GridSearchCV(DecisionTreeClassifier(), param_grid, cv=5, scoring='balanced_accuracy')\n",
        "    grid_search.fit(X=features, y=target)\n",
        "    \n",
        "    # this is the estimator chosen by the search\n",
        "    print(\"Best estimator: \", grid_search.best_estimator_)\n",
        "\n",
        "    # this is the best performance during training (balanced accuracy score)\n",
        "    print(\"Best cross-validation score: \", grid_search.best_score_)\n",
        "\n",
        "    # result of grid search\n",
        "    print(\"Best parameters: \", grid_search.best_params_)\n",
        "    \n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "id": "DBd0AaDFiT09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The most common parameters deemed best were:\n",
        "* criterion: 'gini'\n",
        "* class_weight: 'balanced'\n",
        "* max_depth: 5"
      ],
      "metadata": {
        "id": "yixVb0H5nuy8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_estimator = DecisionTreeClassifier(class_weight='balanced', max_depth=5)\n",
        "\n",
        "# classify based with the selected features and best estimator\n",
        "classifier_cv(df_selected, best_estimator)"
      ],
      "metadata": {
        "id": "gXGkFSkWoFPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDraDM60DaBK"
      },
      "source": [
        "### 3.5. Model Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our model was developed using cross validation and resampling on the training split only. Here, we train the model on our selected and scaled training data, and then test on the scaled and selected testing split."
      ],
      "metadata": {
        "id": "4ZBr71ZgoZd6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# preparing the training data for retraining the model\n",
        "selected_training_df = training_df[selected_features]\n",
        "\n",
        "# split the dataset into features and target\n",
        "train_features, train_target = features_and_target(selected_training_df)\n",
        "\n",
        "# fit scalar to training data\n",
        "scaler.fit(train_features) \n",
        "\n",
        "# scale training data\n",
        "train_features_scaled = scaler.transform(train_features)"
      ],
      "metadata": {
        "id": "5c14KF4EiTtd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preparing test data based on tuning above\n",
        "selected_testing_df = testing_df[selected_features]\n",
        "\n",
        "# split the dataset into features and target\n",
        "test_features, test_target = features_and_target(selected_testing_df)\n",
        "\n",
        "# scale testing data based on the scalar fit to the training data\n",
        "test_features_scaled = scaler.transform(test_features)"
      ],
      "metadata": {
        "id": "hvDO7TCw-s9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model trained using training data and optimized parameters\n",
        "model = DecisionTreeClassifier(class_weight='balanced', max_depth=5).fit(X=train_features_scaled, y=train_target)\n",
        "\n",
        "print(f\"DecisionTree Classifier with Tuned Parameters and Selected Features:\")\n",
        "# training data metrics\n",
        "print(\"\\tPrediction accuracy on the training data:\", format(model.score(train_features_scaled, train_target)*100, \".2f\"))\n",
        "\n",
        "balanced_accuracy_training = balanced_accuracy_score(train_target, model.predict(X=train_features_scaled))\n",
        "print(\"\\tBalanced accuracy score (training):\",  format(balanced_accuracy_training * 100, \".2f\"))\n",
        "print(\"\")\n",
        "\n",
        "# testing data mertics\n",
        "print(\"\\tPrediction accuracy on the test data:\", format(model.score(test_features_scaled, test_target)*100, \".2f\"))\n",
        "\n",
        "balanced_accuracy_test = balanced_accuracy_score(test_target, model.predict(X=test_features_scaled))\n",
        "print(\"\\tBalanced accuracy score (testing):\",  format(balanced_accuracy_test * 100, \".2f\"))"
      ],
      "metadata": {
        "id": "XJoYJnX6-s0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### _Prediction of 2021 Cy Young Winners Using our Model_"
      ],
      "metadata": {
        "id": "Y9Bjr4O3ZqoW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# format 2021 dataset\n",
        "selected_2021 = combined_2021[selected_features].dropna()\n",
        "\n",
        "# split the dataset into features and target\n",
        "features_2021, target_2021 = features_and_target(selected_2021)\n",
        "\n",
        "# scale the split a single partition of the data to use for feature selection\n",
        "scaler.fit(train_features) \n",
        "\n",
        "features_2021_scaled = scaler.transform(features_2021)"
      ],
      "metadata": {
        "id": "3lvj_0zcZ1G7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model trained using training data and optimized parameters\n",
        "model = DecisionTreeClassifier(class_weight='balanced', max_depth=5).fit(X=train_features_scaled, y=train_target)\n",
        "\n",
        "winners = model.predict(X=features_2021)\n",
        "\n",
        "predicted_winners = 0\n",
        "for p in winners:\n",
        "    if p == 1:\n",
        "        predicted_winners + 1\n",
        "print(predicted_winners)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCw-5JSfZ03R",
        "outputId": "4f96c596-b073-458e-eb1d-bb4d6faf5c45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our model could not predict any Cy Young award winners for 2021. This could be due to the imbalance of our training data: our model could not learn enough information about the characteristics of a \"winner\", so it concluded that all players did not fit that class."
      ],
      "metadata": {
        "id": "QA831Z8SaWEN"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCm-nI2cDaBK"
      },
      "source": [
        "<a id=\"4\"></a>\n",
        "<hr style=\"height:2px; border:none; color:black; background-color:black;\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHiL6GSUDaBL"
      },
      "source": [
        "## 4. DISCUSSION\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "&emsp;&emsp;We compared Support Vector Machine (SVM), Decision Tree classifier, k-Nearest Neighbors (kNN), and Logistic Regression. Decision tree and SVM (LinearSVC) both performed well, with higher accuracy than kNN or Logistic Regression. However, Decision tree seemed to have slightly higher/more consistent accuracies than LinearSVC, so we decided to use that for our final algorithm. We did use grid search with both LinearSVC and decision trees to find their best parameters, but decision tree still beat out LinearSVC in terms of performance. For LinearSVC, we adjusted C and class_weight. C is the regularization parameter, and class_weight either doesn’t balance classes or uses C to balance them. For Decision Tree, we used grid search to try different values for criterion, max_depth, and class_weight. Criterion measures the quality of a split, max_depth determines the maximum depth of the tree, and class_weight weighs the classes if necessary. After looking at both LinearSVC and Decision Tree with ideal parameters, Decision Tree still slightly outperformed LinearSVC, so that was the algorithm we decided to use for our predictive model. \n",
        "\n",
        "&emsp;&emsp; Based on our findings and analysis of this data, we do not believe that that we can accurately predict the outcome variable of who deserves to win the 2021 Cy Young Awards. One reason is that our model severely overfits the training data (100% accuracy) and cannot be generalized to other years' data. Importantly, our prediction accuracy on the test data was close to 100% at 98.96% with our balanced accuracy score only benig 49.83%. Thus, a seemingly great prediction accuracy is invalidated by the less than ideal balanced accruacy score. \n",
        "\n",
        "&emsp;&emsp; The ethical implications of this project are not large in scope. The problem that this project attempts to solve really only relates to Major League Baseball and the world of professional baseball. Especially since our result is that we cannot form a confident prediction, it is safe to say that our project is not crossing any ethical boundaries of any sort both in the questions that we are asking as well as any potential results. \n",
        "\n",
        "&emsp;&emsp; Our dataset is biased, however. Each time we ran this code, the prediction accuracy values would vary greatly. To address this, a balanced accuracy score was also used to quantify model accuracy. This value is close to 50% for all models, indicating that the models are essentially randomly choosing how to classify players. This situation arises due to the imbalanced, bias nature of our dataset. \n",
        "\n",
        "&emsp;&emsp; This project definitely starts an interesting look into the world of sabermetrics. For future reference, however, there are some steps that could be taken to work towards actually making a confident prediction. Once such step would be to gather more years worth of data. Baseball-reference has many more years of data to scrape. However, since voting trends for the Cy Young have changed over time, going back too far might interfere with making accurate predictions for the current year. Another step to take would be to try using different machine learning algorithms with better parameter tuning. Our methods had inconsistent parameters to tune to, which definitely lead to low confidence in any prediction that our model made. Perhaps there are other algorithms to explore with different parameter tuning methods that could give us a much more confident prediction."
      ],
      "metadata": {
        "id": "6IJoTvUtFqsd"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMt2LDebDaBL"
      },
      "source": [
        "<a id=\"5\"></a>\n",
        "<hr style=\"height:2px; border:none; color:black; background-color:black;\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "db8iVacLDaBL"
      },
      "source": [
        "### CONTRIBUTIONS\n",
        "* Section 1:  Daniel\n",
        "* Section 2:  Daniel and Hannah\n",
        "* Section 3:  Karenna and Hannah\n",
        "* Section 4:  Daniel and Karenna\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F2Zlr-j1DaBL"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "DS3000_FP4_Group10.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}